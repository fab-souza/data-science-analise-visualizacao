![Badge em Desenvolvimento](http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=GREEN&style=for-the-badge)

| :placard: Vitrine.Dev |    |
| -------------  | --- |
| :sparkles: Nome        | **Data Science: an√°lise e visualiza√ß√£o de dados**
| :label: Tecnologias | python
| :rocket: URL         | Notebook no Kaggle
| :fire: Desafio     | Conte√∫do do curso [Data Science: analise e visualiza√ß√£o de dados](https://www.alura.com.br/curso-online-data-science-primeiros-passos)

![](https://user-images.githubusercontent.com/67301805/218529188-eb796695-5693-44b2-85f1-a34b32fb5328.jpg#vitrinedev)

# Sobre o curso üìö

Este √© o primeiro curso da forma√ß√£o Data Science, ministrado pelo instrutor [Guilherme Silveira](https://www.linkedin.com/in/guilhermeazevedosilveira/), em que aprofundei meus conhecimentos sobre o que √© fazer ci√™ncia de dados, ao fazer mais an√°lises explorat√≥rias de um banco de dados, melhorar a visualiza√ß√£o dos gr√°ficos utilizando Matplotlib e Seaborn.

Utilizamos tr√™s bases de dados neste curso, todas relacionadas a filmes. A primeira √© sobre as notas que o usu√°rio atribuiu aos filmes que j√° assistiu, a segunda cont√©m o t√≠tulo dos filmes e seus g√™neros, enquanto a √∫ltima era um dataset mais robusto, pois al√©m do t√≠tulo e dura√ß√£o, h√° informa√ß√µes sobre o or√ßamento, idioma original, sinopse, popularidade, data de lan√ßamento, nota m√©dia e quantidade de votos que o filme recebeu.

![image](https://user-images.githubusercontent.com/67301805/219108327-b5c82f9c-9632-4b52-94f9-81bdad53f1e7.png)
![image](https://user-images.githubusercontent.com/67301805/219108394-02ef69af-db48-4f73-8fb9-538083eb5fa3.png)
![image](https://user-images.githubusercontent.com/67301805/219108492-8e79a70a-2f0e-4143-a5fc-779947e55069.png)




# Minha pr√°tica üë©üèª‚Äçüíª

At√© o momento, eu estava replicando o que aprendi nos cursos da Alura. Ou seja, mostrava o que identifiquei nos dados, usando os m√©todos e bibliotecas que vi no curso. Por√©m, decidi apresentar esta pr√°tica de outra forma, por dois motivos:

- em janeiro, eu terminei de ler o livro [Storytelling com dados](https://altabooks.com.br/produto/storytelling-com-dados/), da Cole Nussbaumer, que √© sobre como melhorar a visualiza√ß√£o de dados. Ao longo do livro, a autora ensina como construir uma narrativa para os dados e deixar a apresenta√ß√£o mais interessante para quem estiver ouvindo/lendo. Mas durante a leitura, tamb√©m comecei a refletir sobre todos os relat√≥rios e apresenta√ß√µes que fiz ao longo da minha vida, tanto acad√™mica quanto profissional, porque eu consegui recordar de situa√ß√µes em que foquei no ‚Äúembelezamento‚Äù do gr√°fico, ao inv√©s de melhorar o texto e facilitar a compreens√£o do ouvinte/leitor.

- e o segundo motivo, √© um outro curso que conclu√≠ recentemente na Alura, o de [Modelos preditivos em dados: detec√ß√£o de fraude](https://www.alura.com.br/curso-online-modelos-preditivos-dados-deteccao-fraude), da instrutora [Sthefanie Monica](https://github.com/sthemonica?tab=overview&from=2023-02-01&to=2023-02-17). Antes de dar in√≠cio a cria√ß√£o do modelo preditivo, a instrutora apresenta o seguinte cen√°rio: 
*Estamos trabalhando em uma startup de dados e precisamos criar um modelo preditivo para uma institui√ß√£o financeira fict√≠cia. Posteriormente, o projeto ser√° adicionado ao portf√≥lio da empresa e apresentado aos futuros clientes*.
Ao longo do curso, decis√µes foram tomadas a partir desta informa√ß√£o e que facilitou minha compreens√£o. 

Entende que h√° uma diferen√ßa entre contextualizar a narrativa com um cen√°rio (mesmo que fict√≠cio), ao inv√©s de exemplificar com uma situa√ß√£o isolada? 

Que √© exatamente o que fiz at√© o momento, explicava brevemente sobre o que se tratava o dataset e resumia os resultados obtidos no notebook.

Portanto, vou criar um contexto para o projeto, inspirada na did√°tica do curso sobre modelos preditivos e tamb√©m para replicar o que aprendi com o livro.

---

Dito isso, para esta pr√°tica, utilizei um dataset dispon√≠vel no [Kaggle](https://www.kaggle.com/) sobre avalia√ß√µes de [barras de chocolate](https://www.kaggle.com/datasets/rtatman/chocolate-bar-ratings), provenientes de diversos pa√≠ses, compostos por diferentes tipos de gr√£o e porcentagem de cacau.

![image](https://user-images.githubusercontent.com/67301805/219493123-06dc2cee-536c-49f3-b5ee-059fd713a275.png)

Neste caso, vamos supor que: 

**Eu preciso fazer a an√°lise explorat√≥ria neste dataset, porque estou prestando consultoria para uma empresa do setor de alimentos que nunca trabalhou com chocolate anteriormente, mas quer entrar neste ramo e desenvolver seu produto. 
Portanto, preciso apresentar os melhores produtos presentes no mercado, os principais concorrentes, de onde eles s√£o, qual gr√£o eles utilizam, qual o pa√≠s de origem do gr√£o e qual a porcentagem de cacau que possui as melhores avalia√ß√µes.**

Decidi explorar os dados da seguinte maneira:

Calcular a m√©dia, ou mediana, das notas para cada vari√°vel. Selecionando os fabricantes com as melhores m√©dias, depois os melhores produtos, assim por diante. A cada etapa, criaria um novo dataframe e exploraria as demais vari√°veis. Por exemplo, ao selecionar os melhores produtos, verificaria de onde eles s√£o, as porcentagens de cacau mais recorrentes, etc.

## Fabricantes: üè≠

Iniciei a an√°lise pelos *Fabricantes*, ao calcular a m√©dia de suas notas. Selecionei os 15 que tiveram as melhores m√©dias e criei um novo dataframe, composto por 49 linhas e 9 colunas. 

![image](https://user-images.githubusercontent.com/67301805/221249766-cf0ac0cf-c901-42b6-9677-b39e540fc1ca.png)

Em que, 6 delas s√£o dos Estados Unidos, 2 da Fran√ßa e mais sete pa√≠ses com 1 empresa cada. 

Em seguida, averiguei qual a porcentagem de cacau mais presente nas barras de chocolate, o top 3 √© composto por 24 produtos com 70% de cacau, 11 com 72% e 4 com 68%. 

Ao fazer a an√°lise do tipo de gr√£o mais utilizado, percebi uma incoer√™ncia do dataset. Quando fiz o **.info()**, tanto a vari√°vel Tipo_grao quanto a Origem_grao, apresentaram apenas 1 linha sem informa√ß√£o, o que considerei ‚Äòok‚Äô para um dataset com 1795 entradas. Mas, no retorno do **groupby()** haviam 9 produtos sem a informa√ß√£o sobre os gr√£os‚Ä¶ ü§∑‚Äç‚ôÄÔ∏è

Enfim, os gr√£os mais presentes s√£o: 14 barras de Trinitario, 10 de Criollo, 9 sem identifica√ß√£o e 3 de Blend.

Finalizando com o pa√≠s de origem dos gr√£os, 14 s√£o da Venezuela, 8 do Peru e 3 sem identifica√ß√£o. 














![image](https://user-images.githubusercontent.com/67301805/220790343-cc77c084-bd21-42e1-adad-77be55631534.png)




# Conclus√£o üèÅ

De acordo com os fabricantes: 

Caso a empresa queira desenvolver um produto que consiga as melhores notas, sugiro verificar o concorrente italiano *Amedei*, fabricante do *Chuao*, que recebeu nota m√°xima na avalia√ß√£o.

Caso a empresa queira ter uma linha de produtos, com avalia√ß√µes consistentes e acima da mediana de todas as notas, sugiro verificar a linha de produtos dos concorrentes *Idilio*, *Matale* e *Patric*. 


## Ferramentas utilizadas üß∞ 
<p> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> 
    <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/>
    <a href="https://seaborn.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://seaborn.pydata.org/_images/logo-mark-lightbg.svg" alt="seaborn" width="40" height="40"/>
    <a href="https://numpy.org/" target="_blank" rel="noreferrer"> <img src="https://numpy.org/images/logo.svg" alt="numpy" width="40" height="40"/>
    </p>
